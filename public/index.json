[{"authors":["admin"],"categories":null,"content":"Nicolas Mollier studiert Data Science im Master an der Universität Tübingen.\n","date":1554595200,"expirydate":-62135596800,"kind":"term","lang":"de","lastmod":1554595200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/author/nicolas-mollier/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/nicolas-mollier/","section":"authors","summary":"Nicolas Mollier studiert Data Science im Master an der Universität Tübingen.","tags":null,"title":"Nicolas Mollier","type":"authors"},{"authors":["吳恩達"],"categories":null,"content":"吳恩達 is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"de","lastmod":-62135596800,"objectID":"da99cb196019cc5857b9b3e950397ca9","permalink":"/author/%E5%90%B3%E6%81%A9%E9%81%94/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E5%90%B3%E6%81%A9%E9%81%94/","section":"authors","summary":"吳恩達 is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.","tags":null,"title":"吳恩達","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Academic\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further talk details can easily be added to this page using Markdown and $\\rm \\LaTeX$ math code.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"de","lastmod":1906549200,"objectID":"96344c08df50a1b693cc40432115cbe3","permalink":"/talk/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example/","section":"talk","summary":"An example talk using Academic's Markdown slides feature.","tags":[],"title":"Example Talk","type":"talk"},{"authors":[],"categories":[],"content":"  Eine Analyse für die Teilnahme an der Titanic Machine Learning Competition auf https://www.kaggle.com/c/titanic. Das Hauptaugenmerk dieser Analyse liegt auf dem Hyperparametertuning per Cross-Validation. Für die Modellierung wird tidymodels -der Nachfolger von caret- verwendet.\nPackages library(tidyverse) library(tidymodels) library(doParallel) library(vip) library(kableExtra) library(modelr)  Get the Data Im ersten Schritt laden wir den Trainingsdatensatz und den Testdatensatz, nachdem wir beide unter https://www.kaggle.com/c/titanic/data heruntergeladen haben.\ntitanic \u0026lt;- read_csv(\u0026quot;train.csv\u0026quot;) titanic_holdout \u0026lt;- read_csv(\u0026quot;test.csv\u0026quot;)  Exploarative Datenanalyse Wir beginnen mit einer kurzen explorativen Datenanalyse.\nDer Datensatz titanic enthält Informationen aus 12 Variablen für 891 Passagiere der Titanic. Abzüglich der Variablen Survived und PassengerId stehen uns zunächst 10 Prädiktoren zur Verfügung.\nglimpse(titanic) ## Rows: 891 ## Columns: 12 ## $ PassengerId \u0026lt;dbl\u0026gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17… ## $ Survived \u0026lt;dbl\u0026gt; 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, … ## $ Pclass \u0026lt;dbl\u0026gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, … ## $ Name \u0026lt;chr\u0026gt; \u0026quot;Braund, Mr. Owen Harris\u0026quot;, \u0026quot;Cumings, Mrs. John Bradley (F… ## $ Sex \u0026lt;chr\u0026gt; \u0026quot;male\u0026quot;, \u0026quot;female\u0026quot;, \u0026quot;female\u0026quot;, \u0026quot;female\u0026quot;, \u0026quot;male\u0026quot;, \u0026quot;male\u0026quot;, \u0026quot;ma… ## $ Age \u0026lt;dbl\u0026gt; 22, 38, 26, 35, 35, NA, 54, 2, 27, 14, 4, 58, 20, 39, 14,… ## $ SibSp \u0026lt;dbl\u0026gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, … ## $ Parch \u0026lt;dbl\u0026gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, … ## $ Ticket \u0026lt;chr\u0026gt; \u0026quot;A/5 21171\u0026quot;, \u0026quot;PC 17599\u0026quot;, \u0026quot;STON/O2. 3101282\u0026quot;, \u0026quot;113803\u0026quot;, \u0026quot;3… ## $ Fare \u0026lt;dbl\u0026gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625… ## $ Cabin \u0026lt;chr\u0026gt; NA, \u0026quot;C85\u0026quot;, NA, \u0026quot;C123\u0026quot;, NA, NA, \u0026quot;E46\u0026quot;, NA, NA, NA, \u0026quot;G6\u0026quot;, \u0026quot;… ## $ Embarked \u0026lt;chr\u0026gt; \u0026quot;S\u0026quot;, \u0026quot;C\u0026quot;, \u0026quot;S\u0026quot;, \u0026quot;S\u0026quot;, \u0026quot;S\u0026quot;, \u0026quot;Q\u0026quot;, \u0026quot;S\u0026quot;, \u0026quot;S\u0026quot;, \u0026quot;S\u0026quot;, \u0026quot;C\u0026quot;, \u0026quot;S\u0026quot;, \u0026quot;S… Beziehung zwischen den Prädiktoren und der zu erklärenden Variablen Survived Als erstes betrachten wir in welcher Beziehung die einzelnen Prädiktoren mit der zu erklärenden Variablen Survived stehen.\ntitanic %\u0026gt;% select(Age, Fare, Parch, SibSp, Survived) %\u0026gt;% mutate(Survived = factor(Survived)) %\u0026gt;% pivot_longer(-Survived, names_to = \u0026quot;variable\u0026quot;, values_to = \u0026quot;value\u0026quot;) %\u0026gt;% ggplot(aes(x = Survived, y = value, fill = Survived)) + geom_boxplot() + facet_wrap(~variable, scales = \u0026quot;free\u0026quot;) + theme(axis.title = element_blank()) Die Grafik zeigt inwieweit sich die Verteilungen der numerischen Varaiblen unterscheiden, je nachedm ob die jeweiligen Passagiere (Observationen) überlebt haben oder nicht. Zur Überprüfung der Unterschiede in Alter und Ticketpreis wurden je eine ANOVA durchgeführt.\n# Age and Survived anova_age_survived \u0026lt;- anova(aov(Age ~ Survived, data = titanic)) p_anova_age_survived \u0026lt;- anova_age_survived$`Pr(\u0026gt;F)`[1] # Fare and Survived anova_fare_survived \u0026lt;- anova(aov(Fare ~ Survived, data = titanic)) p_anova_fare_survived \u0026lt;- anova_fare_survived$`Pr(\u0026gt;F)`[1] Die Überlebenden waren zwar statistisch signifikant jünger (ANOVA: p-Wert = 3.91%). Allerdings beträgt der Unterschied nur 2.3 Jahre (28.3 vs. 30.6) Die Überlebenden besaßen aber deutlich höherpreisige Tickets als die Verstorbenen (48.4 vs. 22.1, ANOVA: p-Wert \u0026lt; 0.01).\nDie nachfolgende Grafik zeigt die Beziehung der Variablen Embarked, Pclass und Sex mit der zu erklärenden Variablen Survived. Auf der y-Achse sind die Überlebensraten abgetragen.\ntitanic %\u0026gt;% select(Embarked, Sex, Pclass, Survived) %\u0026gt;% filter(Embarked != \u0026quot;NA\u0026quot;) %\u0026gt;% mutate_at(vars(Embarked, Sex, Pclass), as.factor) %\u0026gt;% pivot_longer(-Survived, names_to = \u0026quot;variable\u0026quot;, values_to = \u0026quot;value\u0026quot;) %\u0026gt;% group_by(variable, value) %\u0026gt;% summarise(mean = mean(Survived, na.rm = T)) %\u0026gt;% mutate(variable = factor(variable)) %\u0026gt;% ggplot(aes(value, mean)) + geom_bar(stat = \u0026quot;identity\u0026quot;, na.rm = T) + facet_grid(~variable, scale = \u0026quot;free_x\u0026quot;, space = \u0026quot;free\u0026quot;) + labs(x = \u0026quot;\u0026quot;, y = \u0026quot;Überlebensrate\u0026quot;) Passagiere der ersten Klasse überlebten deutlich häufiger als die Passagiere der zweiten bzw. dritten Klasse. Am deutlichsten ist der Unterschied der Überlebensrate zwischen Männern und Frauen. Während Frauen zu 74.20% überlebten, waren es unter den männlichen Passagieren nur 18.89%.\n Kollinearität der Prädiktoren Wir werfen einen kurzen Blick auf die Kollinearität der Prädiktoren.\ntitanic %\u0026gt;% select(Age, Fare, Parch, SibSp, Pclass) %\u0026gt;% na.omit() %\u0026gt;% cor() %\u0026gt;% corrplot::corrplot.mixed() Die numerischen Prädiktoren weisen keine erhöhten Korrelationen untereinander auf. Dennoch werden wir zur Sicherheit vor der Modellierung im Schritt recipe einen Algorithmus auf die Daten anwenden, der Prädiktoren mit zu großer absoluter Korrelation mit anderen Prädiktoren entfernt.\n Schiefe der Verteilungen Als nächstes betrachten wir die Verteilungen der Prädiktorvariablen. Zu schiefe Verteilungen können bei der Prognose zu Problemen führen.\ntitanic %\u0026gt;% select(Age, Fare, SibSp, Parch) %\u0026gt;% pivot_longer(1:4, names_to = \u0026quot;variable\u0026quot;, values_to = \u0026quot;value\u0026quot;) %\u0026gt;% ggplot(aes(value)) + geom_histogram() + facet_wrap(~variable, scales = \u0026quot;free\u0026quot;) + labs(x = \u0026quot;\u0026quot;, y = \u0026quot;\u0026quot;) Insbesondere die Variable Fare weist eine enorm rechtsschiefe Verteilung auf. Deshalb werden wir vor der Modellierung die Yeo-Johnson Transformation anwenden, um die Verteilung von Fare symmetrischer zu machen.\n  Entfernung von Variablen Overfitting Um ein Overfitting zu vermeiden, möchten wir Variablen, die den jeweiligen Passagier eindeutig oder nahezu eindeutig identifizieren, nicht zur Modellierung verwenden. Um diese Variablen herauszufinden, betrachten wir die Anzahl der “unique values” der Variablen des Typs character.\ntitanic %\u0026gt;% select_if(is.character) %\u0026gt;% map(unique) %\u0026gt;% map_df(length) %\u0026gt;% pivot_longer(Name:Embarked, names_to = \u0026quot;variable\u0026quot;, values_to = \u0026quot;# unique values\u0026quot;) %\u0026gt;% knitr::kable()    variable  # unique values      Name  891    Sex  2    Ticket  681    Cabin  148    Embarked  4     Die Variablen mit Typ character haben teilweise sehr viele verschiedene Werte. Mit den Variablen Name und Ticket sind die jeweiligen Passagiere nahezu eindeutig identifizierbar. Um ein Overfitting zu vermeiden, werden Name und Ticket deshalb nicht zur Modellierung benutzt.\n  Missings Für die Schätzung (Imputation) fehlender Werte verwenden wir Bagged Tree Imputation. Enthält eine Variable allerdings zu viele Missings, so macht selbst eine Schätzung der fehlenden Werte keinen Sinn mehr und die Variable sollte entfernt werden.\nna_prop_cabin \u0026lt;- titanic %\u0026gt;% count(Cabin) %\u0026gt;% mutate(prop = n / sum(n)) %\u0026gt;% arrange(desc(prop)) %\u0026gt;% slice_head(n = 1) %\u0026gt;% select(prop) %\u0026gt;% as_vector() Die Variable Cabin enthält zu 77.10% fehlende Werte (NAs). Aus diesem Grund wird auch diese Variable nicht zur Modellierung verwendet.\nInsegesamt werden also Cabin, Name und Ticket aus dem Datensatz entfernt.\ntitanic \u0026lt;- titanic %\u0026gt;% select(-Cabin, -Name, -Ticket) Neben der bereits entfernten Variablen Cabin weisen noch zwei weitere Variablen fehlende Werte auf.\nsummary(titanic) ## PassengerId Survived Pclass Sex ## Min. : 1.0 Min. :0.0000 Min. :1.000 Length:891 ## 1st Qu.:223.5 1st Qu.:0.0000 1st Qu.:2.000 Class :character ## Median :446.0 Median :0.0000 Median :3.000 Mode :character ## Mean :446.0 Mean :0.3838 Mean :2.309 ## 3rd Qu.:668.5 3rd Qu.:1.0000 3rd Qu.:3.000 ## Max. :891.0 Max. :1.0000 Max. :3.000 ## ## Age SibSp Parch Fare ## Min. : 0.42 Min. :0.000 Min. :0.0000 Min. : 0.00 ## 1st Qu.:20.12 1st Qu.:0.000 1st Qu.:0.0000 1st Qu.: 7.91 ## Median :28.00 Median :0.000 Median :0.0000 Median : 14.45 ## Mean :29.70 Mean :0.523 Mean :0.3816 Mean : 32.20 ## 3rd Qu.:38.00 3rd Qu.:1.000 3rd Qu.:0.0000 3rd Qu.: 31.00 ## Max. :80.00 Max. :8.000 Max. :6.0000 Max. :512.33 ## NA\u0026#39;s :177 ## Embarked ## Length:891 ## Class :character ## Mode :character ## ## ## ##  Die Variable Age hat 177 Observationen mit fehlendem Wert. Bei Variablen des Typs character sind fehlende Werte durch bloßen Aufruf der Funktion summary() nicht erkennbar. Durch zweifachen Aufruf der Funktion map() können alle verbleibenden Variablen mit fehlenden Werten identifiziert werden.\nmap(titanic, is.na) %\u0026gt;% map_df(sum) %\u0026gt;% pivot_longer(PassengerId:Embarked, names_to = \u0026quot;variable\u0026quot;, values_to = \u0026quot;missings\u0026quot;) %\u0026gt;% filter(missings \u0026gt; 0) %\u0026gt;% knitr::kable()    variable  missings      Age  177    Embarked  2     Die Variable Embarked besitzt 2 fehlende Werte. Im Schritt recipe wird die Schätzung der fehlenden Werte der Variablen Age und Embarked mithilfe von Bagged Trees anhand der Ausprägungen der anderen Variablen des jeweiligen Passagiers spezifiziert.\n Data Split Bevor wir mit der Modellierung beginnen, wird der Datensatz titanic in den Trainingsdatensatz titanic_train und den Testdatensatz titanic_test aufgesplittet. Dabei wird Stratified Sampling verwendet, um zu erreichen, dass die Verteilung von Überlebenden und Verstorbenen in beiden Datensätzen etwa gleich groß ist.\nset.seed(1234) titanic_split \u0026lt;- initial_split(titanic, strata = Survived) titanic_train \u0026lt;- training(titanic_split) titanic_test \u0026lt;- testing(titanic_split) Insgesamt haben wir also drei Datensätze: Den Trainingsdatensatz titanic_train an dem wir mit 10-fold Cross Validation die Werte der jeweiligen Hyperparameter der Modelle bestimmen. Der Testdatensatz titanic_test andem wir die Performance des durch Cross Validation gefundenen besten Modells auf einem, dem Modell unbekannten, Datensatz testen. Und den Datensatz titanic_holdout, bei dem wir nicht wissen, ob die Passagiere überlebt haben oder nicht und für den wir diese Werte im Rahmen der Kaggle Competition prognostizieren müssen.\n Modellierung Die Modellierung mit tidymodels kann in folgende Schritte unterteilt werden. Zunächst wird ein sogenanntes Rezept erstellt, dass alle Pre-Processing Schritte wie Imputation und Transformationen von Variablen umfasst. Danach wird die sogenannte Modellspezifikation vorgenommen. Danach werden Rezept und Modellspezifikation im sogenannten Workflow zusammengefasst. Dieser Workflow wird dann genutzt, um das Hyperparametertuning, die Validierung des besten Modells und die abschließende Prognose für die Competition zu erstellen.\nRecipe Zunächst wird mit der Funktion recipe() festgelegt, welche Pre-Processing Schritte durchzuführen sind. Hier wird umgesetzt, was wir im Rahmen der explorativen Datenanalysen herausgefunden haben. PClass und Survived werden zu Faktorvariablen umgewandelt. Fehlende Werte der Variablen Age und Embarked werden per Bagging geschätzt und auf die Variable Fare wird die Yeo-Johnson Transformation angewendet.\ntitanic_rec \u0026lt;- recipe(Survived ~ ., data = titanic_train) %\u0026gt;% update_role(PassengerId, new_role = \u0026quot;ID\u0026quot;) %\u0026gt;% step_mutate(Pclass = factor(Pclass, labels = c(\u0026quot;first\u0026quot;, \u0026quot;second\u0026quot;, \u0026quot;third\u0026quot;)) %\u0026gt;% fct_rev()) %\u0026gt;% step_mutate(Survived = factor(Survived)) %\u0026gt;% step_bagimpute(all_predictors()) %\u0026gt;% step_YeoJohnson(Fare) %\u0026gt;% #step_dummy(Pclass, Embarked, Sex) %\u0026gt;% prep() Um zu überprüfen, welche Auswirkung die Yeo-Johnson Transformation auf die Verteilung der Variablen Fare hat, betrachten wir folgende Grafik. Die Verteilung ist immer noch rechtsschief, aber die Schiefe wurde deutlich reduziert.\nbake(titanic_rec, new_data = titanic) %\u0026gt;% select(Fare) %\u0026gt;% mutate(Fare_original = titanic$Fare) %\u0026gt;% rename(Fare_transformed = Fare) %\u0026gt;% pivot_longer(1:2, names_to = \u0026quot;variable\u0026quot;, values_to = \u0026quot;values\u0026quot;) %\u0026gt;% mutate(variable = factor(variable)) %\u0026gt;% ggplot(aes(x = values, fill = variable)) + geom_histogram() + facet_grid(~variable, scales = \u0026quot;free\u0026quot;) + theme(legend.position = \u0026quot;none\u0026quot;) %\u0026gt;% labs(x = \u0026quot;\u0026quot;, y = \u0026quot;\u0026quot;)  Modellspezifikation und Workflow Im nächsten Schritt wird das Modell spezifiziert. Wir wählen ein Random Forest Modell zur Klassifizierung, welches als Engine das Paket ranger verwendet. Die Hyperparameter mtry, trees und min_n erhalten Platzhalter, da sie erst noch im nächsten Schritt per Cross Validation bestimmt werden.\nrf_spec \u0026lt;- rand_forest( mode = \u0026quot;classification\u0026quot;, mtry = tune(), trees = tune(), min_n = tune()) %\u0026gt;% set_engine(\u0026quot;ranger\u0026quot;, importance = \u0026quot;impurity\u0026quot;) Das angefertigte Rezept und die Modellspezifikation werden im sogenannten Workflow zusammengefasst.\nrf_wflow \u0026lt;- workflow() %\u0026gt;% add_recipe(titanic_rec) %\u0026gt;% add_model(rf_spec)  Hyperparametertuning Zur Durchführung des Hyperparametertuning werden 10 Folds aus dem Trainingsdatensatz gebildet, die jeweils in Analyseset und Assessmentset unterteilt sind. Je Fold wird das Analyseset zum Trainng des Modells genutzt, während anhand des Assessmentsets die Performance bestimmt wird. Auch hier nutzen wir Stratified Sampling.\nset.seed(1234) titanic_train_folds \u0026lt;- vfold_cv(titanic_train, strata = Survived) titanic_train_folds  ## # 10-fold cross-validation using stratification ## # A tibble: 10 x 2 ## splits id ## \u0026lt;list\u0026gt; \u0026lt;chr\u0026gt; ## 1 \u0026lt;split [601/68]\u0026gt; Fold01 ## 2 \u0026lt;split [601/68]\u0026gt; Fold02 ## 3 \u0026lt;split [602/67]\u0026gt; Fold03 ## 4 \u0026lt;split [602/67]\u0026gt; Fold04 ## 5 \u0026lt;split [602/67]\u0026gt; Fold05 ## 6 \u0026lt;split [602/67]\u0026gt; Fold06 ## 7 \u0026lt;split [602/67]\u0026gt; Fold07 ## 8 \u0026lt;split [603/66]\u0026gt; Fold08 ## 9 \u0026lt;split [603/66]\u0026gt; Fold09 ## 10 \u0026lt;split [603/66]\u0026gt; Fold10 Wir bilden ein Grid, dass alle Kombinationen aus den Werten der Hyperparameter enthält. Wir versuchen 7 verschiedene Werte für die Anzahl der pro Split des jeweiligen Decision Trees verwendeten Prädiktoren (mtry), 6 verschiedene Werte für die Anzahl der pro Random Forest verwendeten Decision Trees (trees) und 8 verschiedene Werte für die minimale Anzahl an Observationen, die in einem Knoten eines Decision Trees notwendig ist, um einen Split dieses Knotens in Erwägung zu ziehen. Die Spanne der betrachteten Werte für mtry wird auf 1 bis 7 festgelegt.\nrf_param \u0026lt;- parameters(rf_spec) %\u0026gt;% update(mtry = mtry(range = c(1, 7)), trees = trees(range = c(1, 2500))) %\u0026gt;% finalize(x = titanic_train %\u0026gt;% select(-Survived)) grid_rf \u0026lt;- grid_regular(rf_param, levels = c(mtry = 7, trees = 6, min_n = 8)) grid_rf %\u0026gt;% knitr::kable() %\u0026gt;% kable_styling(bootstrap_options = c(\u0026quot;striped\u0026quot;, \u0026quot;hover\u0026quot;)) %\u0026gt;% scroll_box(width = \u0026quot;35%\u0026quot;, height = \u0026quot;300px\u0026quot;)   mtry  trees  min_n      1  1  2    2  1  2    3  1  2    4  1  2    5  1  2    6  1  2    7  1  2    1  500  2    2  500  2    3  500  2    4  500  2    5  500  2    6  500  2    7  500  2    1  1000  2    2  1000  2    3  1000  2    4  1000  2    5  1000  2    6  1000  2    7  1000  2    1  1500  2    2  1500  2    3  1500  2    4  1500  2    5  1500  2    6  1500  2    7  1500  2    1  2000  2    2  2000  2    3  2000  2    4  2000  2    5  2000  2    6  2000  2    7  2000  2    1  2500  2    2  2500  2    3  2500  2    4  2500  2    5  2500  2    6  2500  2    7  2500  2    1  1  7    2  1  7    3  1  7    4  1  7    5  1  7    6  1  7    7  1  7    1  500  7    2  500  7    3  500  7    4  500  7    5  500  7    6  500  7    7  500  7    1  1000  7    2  1000  7    3  1000  7    4  1000  7    5  1000  7    6  1000  7    7  1000  7    1  1500  7    2  1500  7    3  1500  7    4  1500  7    5  1500  7    6  1500  7    7  1500  7    1  2000  7    2  2000  7    3  2000  7    4  2000  7    5  2000  7    6  2000  7    7  2000  7    1  2500  7    2  2500  7    3  2500  7    4  2500  7    5  2500  7    6  2500  7    7  2500  7    1  1  12    2  1  12    3  1  12    4  1  12    5  1  12    6  1  12    7  1  12    1  500  12    2  500  12    3  500  12    4  500  12    5  500  12    6  500  12    7  500  12    1  1000  12    2  1000  12    3  1000  12    4  1000  12    5  1000  12    6  1000  12    7  1000  12    1  1500  12    2  1500  12    3  1500  12    4  1500  12    5  1500  12    6  1500  12    7  1500  12    1  2000  12    2  2000  12    3  2000  12    4  2000  12    5  2000  12    6  2000  12    7  2000  12    1  2500  12    2  2500  12    3  2500  12    4  2500  12    5  2500  12    6  2500  12    7  2500  12    1  1  18    2  1  18    3  1  18    4  1  18    5  1  18    6  1  18    7  1  18    1  500  18    2  500  18    3  500  18    4  500  18    5  500  18    6  500  18    7  500  18    1  1000  18    2  1000  18    3  1000  18    4  1000  18    5  1000  18    6  1000  18    7  1000  18    1  1500  18    2  1500  18    3  1500  18    4  1500  18    5  1500  18    6  1500  18    7  1500  18    1  2000  18    2  2000  18    3  2000  18    4  2000  18    5  2000  18    6  2000  18    7  2000  18    1  2500  18    2  2500  18    3  2500  18    4  2500  18    5  2500  18    6  2500  18    7  2500  18    1  1  23    2  1  23    3  1  23    4  1  23    5  1  23    6  1  23    7  1  23    1  500  23    2  500  23    3  500  23    4  500  23    5  500  23    6  500  23    7  500  23    1  1000  23    2  1000  23    3  1000  23    4  1000  23    5  1000  23    6  1000  23    7  1000  23    1  1500  23    2  1500  23    3  1500  23    4  1500  23    5  1500  23    6  1500  23    7  1500  23    1  2000  23    2  2000  23    3  2000  23    4  2000  23    5  2000  23    6  2000  23    7  2000  23    1  2500  23    2  2500  23    3  2500  23    4  2500  23    5  2500  23    6  2500  23    7  2500  23    1  1  29    2  1  29    3  1  29    4  1  29    5  1  29    6  1  29    7  1  29    1  500  29    2  500  29    3  500  29    4  500  29    5  500  29    6  500  29    7  500  29    1  1000  29    2  1000  29    3  1000  29    4  1000  29    5  1000  29    6  1000  29    7  1000  29    1  1500  29    2  1500  29    3  1500  29    4  1500  29    5  1500  29    6  1500  29    7  1500  29    1  2000  29    2  2000  29    3  2000  29    4  2000  29    5  2000  29    6  2000  29    7  2000  29    1  2500  29    2  2500  29    3  2500  29    4  2500  29    5  2500  29    6  2500  29    7  2500  29    1  1  34    2  1  34    3  1  34    4  1  34    5  1  34    6  1  34    7  1  34    1  500  34    2  500  34    3  500  34    4  500  34    5  500  34    6  500  34    7  500  34    1  1000  34    2  1000  34    3  1000  34    4  1000  34    5  1000  34    6  1000  34    7  1000  34    1  1500  34    2  1500  34    3  1500  34    4  1500  34    5  1500  34    6  1500  34    7  1500  34    1  2000  34    2  2000  34    3  2000  34    4  2000  34    5  2000  34    6  2000  34    7  2000  34    1  2500  34    2  2500  34    3  2500  34    4  2500  34    5  2500  34    6  2500  34    7  2500  34    1  1  40    2  1  40    3  1  40    4  1  40    5  1  40    6  1  40    7  1  40    1  500  40    2  500  40    3  500  40    4  500  40    5  500  40    6  500  40    7  500  40    1  1000  40    2  1000  40    3  1000  40    4  1000  40    5  1000  40    6  1000  40    7  1000  40    1  1500  40    2  1500  40    3  1500  40    4  1500  40    5  1500  40    6  1500  40    7  1500  40    1  2000  40    2  2000  40    3  2000  40    4  2000  40    5  2000  40    6  2000  40    7  2000  40    1  2500  40    2  2500  40    3  2500  40    4  2500  40    5  2500  40    6  2500  40    7  2500  40      Insgesamt erhalten wir 336 Kombinationsmöglichkeiten für die Hyperparameter. Für jede dieser Kombinationen wird pro Fold ein Random Forest mit jeweils bis zu 2500 Decision Trees trainiert. Das ergibt insgesamt 3360 Random Forests. Um die Zeit zu reduzieren, die für das Trainieren all dieser Random Forests bzw. Decision Trees notwendig ist, verwenden wir Parallel Processing.\nall_cores \u0026lt;- parallel::detectCores(logical = FALSE) doParallel::registerDoParallel(cores = all_cores) In diesem Schritt findet das Training der 3360 Random Forests im Rahmen des Hyperparametertunings statt. Dazu wird der bereits definierte Workflow zusammen mit dem bereits spezifizierten Grid der zu testenden Parameterwerte und den gebildeten Folds in der Funktion tune_grid verwendet.\ntune_rf \u0026lt;- tune_grid( rf_wflow, resamples = titanic_train_folds, grid = grid_rf, control = control_grid(save_pred = T) )  Visualisierung Nachdem die Modelle trainiert wurden, visualisieren wir die Ergebnisse der Cross Validation.\nAccuracy und AUC Als mögliche Werte für die Anzahl der verwendeten Trees pro Random Forest wurden die Werte 1, 500, 1000, 1500, 2000 und 2500 verwendet.\ntune_rf %\u0026gt;% collect_metrics() %\u0026gt;% filter(.metric == \u0026quot;accuracy\u0026quot;) %\u0026gt;% mutate(mtry = factor(mtry)) %\u0026gt;% ggplot(aes(x = min_n, y = mean, color = mtry)) + geom_line() + geom_point() + facet_wrap(~trees, labeller = \u0026quot;label_both\u0026quot;) + labs(x = \u0026quot;Minimal Node Size (min_n)\u0026quot;, y = \u0026quot;Accuracy\u0026quot;) Die Grafik zeigt, dass -wie zu erwarten- die am schlechtesten performenden Modelle solche sind, die nur aus einem Tree bestehen. Ob 500, 1000, 15000, 2000 oder 2500 Trees pro Random Forest verwendet werden, scheint keinen Unterschied zu machen. Die Modelle mit einer Minimal Node Size (min_n) von etwa 20 bis 25 scheinen die besten Ergebnisse für die Metrik Accuracy zu erzielen. Für die Anzahl der pro Knoten betrachteten Prädiktoren scheint ein Wert von etwa 3 gut zu funktionieren, wenn man die Kurven für die Accuracy betrachtet. Dieser Eindruck wird durch die nachfolgende Grafik bestätigt.\ntune_rf %\u0026gt;% collect_metrics() %\u0026gt;% filter(.metric == \u0026quot;accuracy\u0026quot; \u0026amp; trees != 1) %\u0026gt;% select(mean, mtry:min_n) %\u0026gt;% pivot_longer(mtry:min_n, names_to = \u0026quot;parameter\u0026quot;, values_to = \u0026quot;value\u0026quot;) %\u0026gt;% ggplot(aes(value, mean, color = parameter)) + geom_point() + geom_smooth() + facet_wrap(~parameter, scales = \u0026quot;free_x\u0026quot;) + labs(x = \u0026quot;\u0026quot;, y = \u0026quot;Accuracy\u0026quot;)  ROC Wir visualisieren die ROC Kurven, wobei wir jeweils die Kurven durch eine der drei Hyperparameter gruppieren und einfärben. Für die Metrik Area under the Curve (AUC) spielt die Wahl der Hyperparameter insgesamt keine große Rolle, solange man mindestens 500 Trees pro Random Forest verwendet.\ntune_rf %\u0026gt;% collect_predictions() %\u0026gt;% mutate(mtry = factor(mtry)) %\u0026gt;% group_by(mtry) %\u0026gt;% roc_curve(truth = Survived, .pred_1, event_level = \u0026quot;second\u0026quot;) %\u0026gt;% ggplot(aes(x = 1- specificity, y = sensitivity, color = mtry)) + geom_path() + geom_abline(lty = 3, alpha = 0.6) + coord_equal() tune_rf %\u0026gt;% collect_predictions() %\u0026gt;% mutate(min_n = factor(min_n)) %\u0026gt;% group_by(min_n) %\u0026gt;% roc_curve(truth = Survived, .pred_1, event_level = \u0026quot;second\u0026quot;) %\u0026gt;% ggplot(aes(x = 1- specificity, y = sensitivity, color = min_n)) + geom_path() + coord_equal() + geom_abline(lty = 3, alpha = 0.6)  tune_rf %\u0026gt;% collect_predictions() %\u0026gt;% mutate(trees = factor(trees)) %\u0026gt;% group_by(trees) %\u0026gt;% roc_curve(truth = Survived, .pred_1, event_level = \u0026quot;second\u0026quot;) %\u0026gt;% ggplot(aes(x = 1- specificity, y = sensitivity, color = trees)) + geom_path() + coord_equal() + geom_abline(lty = 3, alpha = 0.6)  Was den Verlauf der ROC Kurve betrifft, so hat mtry keinen wesentlichen Einfluss, solange mtry größer als 1 ist. Die Roc Kurven unterschieden sich für verschiedene Werte von min_n ebenfalls nur geringfügig. Die Anzahl der Bäume pro Random Forest spielt für den Verlauf der ROC Kurve keine Rolle, solange die Anzahl mindestens 500 beträgt.\n  Auswahl der Werte der Hyperparameter Nachdem wir visuell untersucht haben, welche Hyperparameterwerte sinnvoll erscheinen, wählen wir nun die endgültigen Werte der Hyperparameter. Dazu verwenden wir als Metriken sowohl die durchschnittliche Accuracy über alle 10 Folds, als auch den Standardfehler der 10 Accuracy Werte pro Parameterkombination. Zwar möchten wir ein Modell mit möglichst hoher durchschnittlicher Accuracy, allerdings ist es auch wichtig, eine Parameterkombination zu wählen, die bei Anwendung auf verschiedenen Datensätzen keine allzu schwankende Performance liefert. Dies ist insbesondere unter dem Aspekt wichtig, dass wie bei der Kaggle Competition Prognosen für nur einen Datensatz liefern müssen bzw. können und nicht wie bei der Cross Validation sozusagen 10 Versuche pro Parameterkombination haben, wobei nur der Durchschnittswert zählt. Dazu speichern wir jeweils die Parameterwerte der gemäß Accuracy bzw. Standardfehler der Accuracywerte 20 besten Modelle.\ncv_rf \u0026lt;-tune_rf %\u0026gt;% collect_metrics() best_accuracy \u0026lt;- tune_rf %\u0026gt;% show_best(metric = \u0026quot;accuracy\u0026quot;, n = 20) %\u0026gt;% arrange(std_err) best_accuracy %\u0026gt;% knitr::kable() %\u0026gt;% kable_styling(bootstrap_options = c(\u0026quot;striped\u0026quot;, \u0026quot;hover\u0026quot;), font_size = 13) %\u0026gt;% scroll_box(height = \u0026quot;300px\u0026quot;)   mtry  trees  min_n  .metric  .estimator  mean  n  std_err  .config      4  2500  23  accuracy  binary  0.8355795  10  0.0113953  Model207    4  1500  23  accuracy  binary  0.8326383  10  0.0116948  Model193    4  500  23  accuracy  binary  0.8341308  10  0.0118343  Model179    3  500  29  accuracy  binary  0.8340430  10  0.0121825  Model220    3  1500  29  accuracy  binary  0.8340430  10  0.0121825  Model234    4  2500  18  accuracy  binary  0.8326389  10  0.0123361  Model165    4  2000  23  accuracy  binary  0.8326383  10  0.0124897  Model200    3  500  23  accuracy  binary  0.8385645  10  0.0127936  Model178    3  1000  23  accuracy  binary  0.8370720  10  0.0128932  Model185    3  2000  18  accuracy  binary  0.8370494  10  0.0129054  Model157    3  2500  18  accuracy  binary  0.8340863  10  0.0130965  Model164    3  2000  29  accuracy  binary  0.8340430  10  0.0131592  Model241    3  1500  12  accuracy  binary  0.8326157  10  0.0133199  Model108    3  500  18  accuracy  binary  0.8385645  10  0.0133398  Model136    3  1000  18  accuracy  binary  0.8355795  10  0.0133708  Model143    3  1500  23  accuracy  binary  0.8385645  10  0.0135240  Model192    3  2500  23  accuracy  binary  0.8385645  10  0.0135240  Model206    2  1500  2  accuracy  binary  0.8356014  10  0.0137483  Model023    3  2000  23  accuracy  binary  0.8400351  10  0.0139487  Model199    3  1500  18  accuracy  binary  0.8356014  10  0.0154207  Model150      Die gemäß Accuracy besten Modelle weisen eine über alle 10 Folds gemittelte Accuracy zwischen 83% und 84% auf. Die Darstellung erfolgt nach Streuung (std_err) sortiert.\nbest_std \u0026lt;- cv_rf %\u0026gt;% filter(.metric == \u0026quot;accuracy\u0026quot;) %\u0026gt;% arrange(std_err) %\u0026gt;% head(n = 20) best_std %\u0026gt;% knitr::kable() %\u0026gt;% kable_styling(bootstrap_options = c(\u0026quot;striped\u0026quot;, \u0026quot;hover\u0026quot;), font_size = 13) %\u0026gt;% scroll_box(height = \u0026quot;300px\u0026quot;)   mtry  trees  min_n  .metric  .estimator  mean  n  std_err  .config      7  2500  40  accuracy  binary  0.8071075  10  0.0058506  Model336    7  1500  40  accuracy  binary  0.8086000  10  0.0067809  Model322    7  2000  40  accuracy  binary  0.8086000  10  0.0067809  Model329    7  1000  40  accuracy  binary  0.8071075  10  0.0070058  Model315    7  500  40  accuracy  binary  0.8100933  10  0.0072176  Model308    7  2500  29  accuracy  binary  0.8116969  10  0.0073757  Model252    6  500  40  accuracy  binary  0.8145935  10  0.0075619  Model307    6  1000  40  accuracy  binary  0.8100933  10  0.0078641  Model314    7  1500  34  accuracy  binary  0.8087118  10  0.0078841  Model280    6  2000  40  accuracy  binary  0.8131009  10  0.0078911  Model328    5  1000  40  accuracy  binary  0.8176012  10  0.0080407  Model313    7  1000  34  accuracy  binary  0.8116749  10  0.0080650  Model273    6  1500  40  accuracy  binary  0.8116084  10  0.0081770  Model321    7  500  34  accuracy  binary  0.8102043  10  0.0082809  Model266    1  1500  34  accuracy  binary  0.8220794  10  0.0082810  Model274    5  500  40  accuracy  binary  0.8190491  10  0.0083412  Model306    6  1000  23  accuracy  binary  0.8177561  10  0.0086040  Model188    7  2000  34  accuracy  binary  0.8131675  10  0.0086765  Model287    6  1500  23  accuracy  binary  0.8177122  10  0.0087017  Model195    6  2500  40  accuracy  binary  0.8131236  10  0.0087449  Model335      best_params \u0026lt;- best_accuracy %\u0026gt;% slice_head(n = 1) %\u0026gt;% select(mtry, trees, min_n) Bei den gemäß Standardfehler der Accuracywerte besten Modellen beträgt die durchschnittliche Accuracy zwischen 80% und 82%. Als endgültige Parameter wählen wir die Werte des Modells, dass unter den gemäß Accuracy 20 besten Modellen die geringste Streuung aufweist. Dieses Modell erzielte bei der Cross Validation eine deutlich überdurchschnittliche Accuracy und gleichzeitig eine unterdurchschnittliche Streuung. Der jeweilige Wert des gewählten Modells ist in den folgenden Boxplots durch einen roten Punkt gekennzeichnet.\nbest_params_metrics \u0026lt;- best_accuracy %\u0026gt;% slice_head(n = 1) %\u0026gt;% select(Accuracy = mean, Streuung = std_err) ref_point \u0026lt;- best_params_metrics %\u0026gt;% pivot_longer(Accuracy:Streuung, names_to = \u0026quot;metric\u0026quot;, values_to = \u0026quot;values\u0026quot;) cv_rf %\u0026gt;% filter(.metric == \u0026quot;accuracy\u0026quot;) %\u0026gt;% select(Accuracy = mean, Streuung = std_err) %\u0026gt;% pivot_longer(Accuracy:Streuung, names_to = \u0026quot;metric\u0026quot;, values_to = \u0026quot;value\u0026quot;) %\u0026gt;% ggplot(aes(value)) + geom_boxplot() + geom_point(data = ref_point, aes(x = values, y = 0), color = \u0026quot;red\u0026quot;, size = 3) + facet_wrap(~metric, scales = \u0026quot;free\u0026quot;) + labs(x = \u0026quot;\u0026quot;, y = \u0026quot;\u0026quot;) Somit verwenden wir sowohl zur Validierung am Testdatensatz als auch zur Prognose am Datensatz titanic_holdout die Parameterwerte:\n mtry = 4 trees = 2500 min_n = 23  Abschließend testen wir das Modell an dem Testdatensatz titanic_test, der nicht zur Model Selection verwendet wurde. Dieser Test dient dazu, eine realistische Einschätzung bezüglich der Performance unseres Modells an neuen Daten zu erhalten.\nset.seed(1234) rf_fit_split \u0026lt;- rf_wflow %\u0026gt;% finalize_workflow(parameters = best_params) %\u0026gt;% last_fit(split = titanic_split) test_metrics \u0026lt;- rf_fit_split %\u0026gt;% collect_metrics() test_metrics %\u0026gt;% knitr::kable()    .metric  .estimator  .estimate      accuracy  binary  0.8288288    roc_auc  binary  0.8823100     Bei der Prognose an dem Testdatensatz titanic_test erzielt das Modell eine Accuracy von 82.9%.\nDie wichtigsten Prädiktoren unseres Modells können mit der Funktion vip() visualisiert werden.\nrf_fit_split %\u0026gt;% pluck(\u0026quot;.workflow\u0026quot;, 1) %\u0026gt;% pull_workflow_fit() %\u0026gt;% vip(num_features = 7) Die wichtigste Variable ist mit Abstand das Geschlecht, gefolgt von der Höhe des Ticketpreises und dem Alter.\n  Kaggle Submission Abschließend erstellen wir die Prediction für die Submission auf Kaggle.\nlast_rf_fit \u0026lt;- rf_wflow %\u0026gt;% finalize_workflow(parameters = best_params) %\u0026gt;% fit(data = titanic) titanic_holdout \u0026lt;- titanic_holdout %\u0026gt;% mutate(Survived = NA) final_pred \u0026lt;- last_rf_fit %\u0026gt;% extract_model() %\u0026gt;% predict(bake(titanic_rec, titanic_holdout), type = \u0026quot;response\u0026quot;) final_pred_binary \u0026lt;- ifelse(final_pred$predictions[,2] \u0026gt; 0.5, 1, 0) %\u0026gt;% factor(levels = c(0, 1)) submission_df \u0026lt;- data.frame(PassengerId = titanic_holdout$PassengerId, Survived = final_pred_binary) write_csv(submission_df, \u0026quot;submission_kaggle.csv\u0026quot;) Das Modell erzielt bei der Competition eine Accuracy von 79.2%. Damit liegt das Modell unter den Top 8% der Submissions.\n ","date":1599004800,"expirydate":-62135596800,"kind":"page","lang":"de","lastmod":1599056709,"objectID":"5210189bdf9165e6b5f26c08cc419f25","permalink":"/post/random-forest-hyperparametertuning-mit-tidymodels-im-rahmen-der-kaggle-machine-learning-competition-titanic/","publishdate":"2020-09-02T00:00:00Z","relpermalink":"/post/random-forest-hyperparametertuning-mit-tidymodels-im-rahmen-der-kaggle-machine-learning-competition-titanic/","section":"post","summary":"Eine Analyse für die Teilnahme an der Titanic Machine Learning Competition auf https://www.kaggle.com/c/titanic. Das Hauptaugenmerk dieser Analyse liegt auf dem Hyperparametertuning per Cross-Validation. Für die Modellierung wird tidymodels -der Nachfolger von caret- verwendet.","tags":["Hyperparametertuning","tidymodels","Predictive Modeling"],"title":"Random Forest: Hyperparametertuning mit tidymodels im Rahmen der Titanic Machine Learning Competition auf Kaggle","type":"post"},{"authors":[],"categories":[],"content":" Der Fokus dieser Analyse liegt auf dem Hyperparametertuning per Cross-Validation. Insbesondere habe ich die Cross Validation durch Schleifen selbst implementiert statt z.B. caret bzw. tidymodels dafür zu verwenden. Für die Modellierung wurde Boosting genutzt. Der verwendete Datensatz stammt aus der Titanic Machine Learning Competition auf Kaggle: https://www.kaggle.com/c/titanic/data. Zwar wurde eine Auswahl aus den zur Verfügung stehenden Prädiktoren getroffen. Eine elaborierte analytische Auswahl der zu verwendenden Prädiktoren und deren Transformation wurden allerdings ausgeklammert. Für eine vollumfängliche Analyse inklusive aller Schritte des Predictive Modeling Workflows siehe Random Forest: Hyperparametertuning mit tidymodels im Rahmen der Titanic Machine Learning Competition\nPackages library(tidyverse) library(knitr) library(kableExtra) library(caret) library(gbm) library(scales) library(e1071)  Load the Data Im ersten Schritt laden wir den Trainingsdatensatz und den Testdatensatz, nachdem wir beide unter https://www.kaggle.com/c/titanic/data heruntergeladen haben. Anschließend verknüpfe ich den Trainings- und Testdatensatz zu einem Datensatz, um das Pre-Processing für beide gleichzeitig durchführen zu können. Dazu ist es notwendig, die Observationen der Trainingsdaten als solche kenntlich zu machen und bei den Testdaten die Variable Survived zu ergänzen, welche in jeder der Testobservationen den Wert NA enthält.\ntrain \u0026lt;- read.csv(file = \u0026quot;train.csv\u0026quot;, header = TRUE, stringsAsFactors = FALSE) test \u0026lt;- read.csv(file = \u0026quot;test.csv\u0026quot;, header = TRUE, stringsAsFactors = FALSE) PassengerId_submission \u0026lt;- test$PassengerId train$IsTrain \u0026lt;- rep(TRUE, nrow(train)) test$IsTrain \u0026lt;- rep(FALSE, nrow(test)) test$Survived \u0026lt;- rep(NA, nrow(test)) titanic \u0026lt;- rbind(train, test)  Data Inspection Der Datensatz enthält 13 Variablen (Die Indikatorvariable IsTrain ausgenommen). Für die Prognose der Variablen Survived stehen also zunächst 11 Variablen zur Verfügung. Der Testdatensatz umfasst 891 Observationen, der Trainingsdatensatz 418.\nglimpse(titanic) head(titanic) summary(titanic)  Unter den Prädiktorvariablen enthalten Age, Fare, Cabin und Embarked fehlende Werte. Die Variable Age enthält 263 fehlende Werte. Bei der Variablen Fare fehlt lediglich bei einer Observation ein Wert. Cabin hat 1014 Missings und Embarked weist 2 Missings auf.\nBei der ersten Untersuchung ist mir eine Unstimmigkeit in den Daten aufgefallen. Zwei Namen tauchen doppelt auf: Connolly, Miss. Kate und Kelly, Mr. James. Allerdings unterscheiden sich die Ausprägungen der anderen Variablen für die jeweiligen Passagiere mit gleichem Namen. PassengerID, Age und Ticketnummer unterscheiden sich jeweils. Außerdem handelt es sich um nicht unübliche Vor- und Nachnamen, sodass davon auszugehen ist, dass es sich um unterschiedliche Personen gleichen Namens handelt.\ntitanic %\u0026gt;% count(Name) %\u0026gt;% filter(n \u0026gt; 1) titanic %\u0026gt;% filter(Name %in% duplicate_names)  Pre-Processing: Umgang mit Missings Sowohl bei Age als auch bei Fare wurden die fehlenden Werte durch den Median der jeweiligen Variablen ersetzt. Zusätzlich wurde eine neue Variable age_missing kreiert, die anzeigt, ob die entsprechende Observation einen fehlenden Wert in der Variable Age aufweist. Für die Variable Cabin wurde eine neue Faktorstufe für die 1014 fehlenden Werte geschaffen. Observationen mit Missings in Variable Embarked werden entfernt, da lediglich zwei Observationen Missings in dieser Variable aufweisen. Würde man an dieser Stelle wie bei Cabin eine neue Faktorstufe (Missing) erzeugen, würde dies später in der Modellierung zu Problemen führen, falls nicht sowohl der Datensatz an dem das Modell trainiert wird als auch der Datensatz, an dem das Modell validiert wird, eine der zwei Observationen mit Ausprägung (Missing) enthalten. Da an späterer Stelle auch Cross-Validation eingesetzt wird, wäre es sehr wahrscheinlich, dass es zu der Situation käme, in der im Testdatensatz Faktorstufen auftauchen, die im Trainingsdatensatz nicht vorkamen.\ntitanic %\u0026gt;% mutate(age_missing = is.na(Age)) %\u0026gt;% group_by(age_missing) %\u0026gt;% summarize(surival_rate = mean(Survived, na.rm = T)) titanic \u0026lt;- titanic %\u0026gt;% mutate(age_missing = is.na(Age)) titanic$Age[is.na(titanic$Age)] \u0026lt;- median(titanic$Age, na.rm = TRUE) titanic$Fare[is.na(titanic$Fare)] \u0026lt;- median(titanic$Fare, na.rm = TRUE) titanic$Cabin[titanic$Cabin == \u0026#39;\u0026#39;] \u0026lt;- NA titanic \u0026lt;- titanic %\u0026gt;% filter(!(Embarked == \u0026#39;\u0026#39;)) titanic \u0026lt;- titanic %\u0026gt;% mutate(cabin_missing = is.na(Cabin))  Die kategorialen Variablen wurden zu Faktorvariablen umgewandelt.\ntitanic$PassengerId \u0026lt;- factor(titanic$PassengerId) titanic$Survived \u0026lt;- factor(titanic$Survived) titanic$Pclass \u0026lt;- factor(titanic$Pclass) titanic$Sex \u0026lt;- factor(titanic$Sex) titanic$Embarked \u0026lt;- factor(titanic$Embarked) titanic$age_missing \u0026lt;- factor(titanic$age_missing) titanic$cabin_missing \u0026lt;- factor(titanic$cabin_missing) #titanic$Cabin \u0026lt;- fct_explicit_na(titanic$Cabin)  Modellierung Zur Prognose der Variablen Survived wurde Boosting verwendet. Zuvor wurde der Gesamtdatensatz nach erfolgter Behandlung der Missings wieder in den Trainingsdatensatz und den Testdatensatz aufgeteilt. Außerdem wurden Variablen, die Passagiere eindeutig oder zumindest sehr genau individuell identifizieren können, nicht als Prädiktoren für die Prognose verwendet, um ein Overfitting der Modelle zu vermeiden. Deshalb wurden die Variablen PassengerId, Name, Ticket und Cabin entfernt.\nunique(titanic$PassengerId) %\u0026gt;% length() unique(titanic$Name) %\u0026gt;% length() unique(titanic$Ticket) %\u0026gt;% length() table(titanic$Cabin) train \u0026lt;- titanic %\u0026gt;% filter(IsTrain) %\u0026gt;% dplyr::select(-PassengerId, -IsTrain, -Name, -Ticket, -Cabin) test \u0026lt;- titanic %\u0026gt;% filter(!IsTrain) %\u0026gt;% dplyr::select(-PassengerId, -IsTrain, -Name, -Ticket, -Cabin, -Survived) Wir spalten die Trainingsdaten train in titanic_train und titanic_test auf. titanic_train wird für das Parametertuning per Cross Validation verwendet. Mit titanic_test bewerten wir das anhand von titanic_train mit den besten Parameterwerten trainierte Modell. Die Accuracy, die wir beim Test an titanic_test erhalten, dient als Schätzung für die Accuracy, die bei Submission auf Kaggle zu erwarten ist.\nset.seed(123) train_split \u0026lt;- caret::createDataPartition(train$Survived, p = 0.75, list = FALSE) titanic_train \u0026lt;- train[train_split,] titanic_test \u0026lt;- train[-train_split,] Boosting Beim Boosting wird jeder Decision Tree auf einer modifizierten Version der Trainingsdaten trainiert. Bei jedem der trainierten Decision Trees werden die Informationen der vorherigen Trees genutzt, indem die Residuals des vorherigen Trees als abhängige Variable genutzt werden. Somit legt jeder folgende Baum besonderes Gewicht auf die Observationen, die von dem vorherigen Baum schlecht vorhergesagt wurden. Wie schnell dieser Lernvorgang geschieht, wird durch den Hyperparameter shrinkage bestimmt. Weitere zu bestimmende Hyperparameter sind die Anzahl der Bäume B und die Anzahl der Splits pro Baum d. Die Hyperparameter werden durch Cross Validation an titanic_train bestimmt. Zunächst wird für jeden Hyperparameter eine Sequenz möglicher Werte gebildet und ein Grid names boosting_parameters erstellt, das alle möglichen Kombinationen der Werte der verschiedenen Hyperparameter enthält. Anschließend bilde ich den Vektor folds der die Indizes enthält, die genutzt werden, um eine Observation innerhalb der Cross Validation entweder dem Training des jeweiligen Modells oder dem Assessment zuzordnen. Für die Implementierung der Cross Validation verwende ich zwei ineinander verschachtelte for-Schleifen. Die erste SChleife iteriert über alle Kombinationen der Hyperparameter, die zweite Schleife iteriert über alle k Stufen der Cross Validation. Jede der k Folds wird in einer der k Stufen einmal dem Assessment des Modells dienen und in den anderen k-1 Stufen zum Trainieren des Modells verwendet.\nntrees \u0026lt;- 1000 lambda \u0026lt;- c(0.001, 0.005, 0.01, 0.015, 0.02, 0.05, 0.1, 0.15) n_splits \u0026lt;- seq(1, 10, 1) boosting_parameters \u0026lt;- expand_grid(ntrees, lambda, n_splits) boosting_parameters \u0026lt;- boosting_parameters %\u0026gt;% mutate(id = 1:nrow(boosting_parameters)) set.seed(123) k \u0026lt;- 5 folds \u0026lt;- sample(1:k, size = nrow(titanic_train), replace = TRUE) boosting_accuracy \u0026lt;- matrix(NA, nrow = k, ncol = nrow(boosting_parameters), dimnames = list(NULL, boosting_parameters$id)) titanic_train_boosting \u0026lt;- titanic_train titanic_train_boosting$Survived \u0026lt;- as.character(titanic_train_boosting$Survived) for(i in 1:nrow(boosting_parameters)){ n.trees \u0026lt;- boosting_parameters$ntrees[i] shrinkage \u0026lt;- boosting_parameters$lambda[i] interaction.depth \u0026lt;- boosting_parameters$n_splits[i] for(j in 1:k){ df_train \u0026lt;- titanic_train_boosting[j != folds,] df_test \u0026lt;- titanic_train_boosting[j == folds,] fit \u0026lt;- gbm(Survived ~ ., data = df_train, n.trees = n.trees, interaction.depth = interaction.depth, shrinkage = shrinkage) pred \u0026lt;- predict(fit, newdata = df_test, type = \u0026quot;response\u0026quot;) pred_binary \u0026lt;- ifelse(pred \u0026gt; 0.5, 1, 0) %\u0026gt;% factor(levels = c(0, 1)) conf_matrix \u0026lt;- caret::confusionMatrix(data = pred_binary, reference = factor(df_test$Survived, levels = c(0,1)), positive = \u0026quot;1\u0026quot;) boosting_accuracy[j, i] \u0026lt;- conf_matrix$overall[\u0026quot;Accuracy\u0026quot;] } } accuracy_mean \u0026lt;- colMeans(boosting_accuracy) cv_accuracy \u0026lt;- accuracy_mean[which.max(accuracy_mean)] best_comb_boosting \u0026lt;- boosting_parameters[which.max(accuracy_mean),] Nachdem beide Schleifen durchlaufen sind, erhalten wir eine Matrix, die für jede Kombination der Hyperparameter in jeder Stufe der Cross Validation die Accuracy des Modells enthält.\ncustom_kable \u0026lt;- function(data, fontsize = 12, fullwidth = FALSE){ knitr::kable(data) %\u0026gt;% kable_styling(font_size = fontsize, full_width = fullwidth) } boosting_accuracy %\u0026gt;% custom_kable() Die höchste Accuracy wird mit einem Modell erzielt, dass 1000 Bäume mit je 6 Splits und einer Lernrate (shrinkage) von 0.015 verwendet. Alle Observationen, die eine prognostizierte Wahrscheinlichkeit von über 0.5 aufweisen, werden als Überlebend klassifiziert. Das Modell mit den gemäß Cross Validation besten Parameterwerten für B, d und shrinkage erzielt eine Cross Validation Accuracy von 84.14%.\nZur abschließenden Bewertung des Modells bewerten wir die Prognosen des Modells mit den soeben gefundenen Hyperparametern an dem Datensatz titanic_test, der nicht an der Auswahl der Hyperparameter beteiligt war.\nntree_best \u0026lt;- best_comb_boosting[[\u0026quot;ntrees\u0026quot;]] n_split_best \u0026lt;- best_comb_boosting[[\u0026quot;n_splits\u0026quot;]] lambda_best \u0026lt;- best_comb_boosting[[\u0026quot;lambda\u0026quot;]] boosting_fit \u0026lt;- gbm(Survived ~ ., data = titanic_train_boosting, n.trees = ntree_best, interaction.depth = n_split_best, shrinkage = lambda_best) pred_boosting_titanic_test \u0026lt;- predict(boosting_fit, newdata = titanic_test, type = \u0026quot;response\u0026quot;) pred_boosting_binary_titanic_test \u0026lt;- ifelse(pred_boosting_titanic_test \u0026gt; 0.5, 1, 0) %\u0026gt;% factor(levels = c(0, 1)) conf_matrix \u0026lt;- caret::confusionMatrix(data = pred_boosting_binary_titanic_test, reference = factor(titanic_test$Survived, levels = c(0,1)), positive = \u0026quot;1\u0026quot;) accuracy \u0026lt;- list() accuracy$boosting \u0026lt;- conf_matrix$overall[\u0026quot;Accuracy\u0026quot;] Die Schätzung der Accuracy beträgt 78.38%. Zum Schluss bestimmen wir mit dem Boosting Modell die Prognosen für den Testdatensatz, speichern sie als csv file ab und reichen sie anschließend auf Kaggle als Submission ein.\ntrain_boosting \u0026lt;- train train_boosting$Survived \u0026lt;- as.character(train_boosting$Survived) mod_boosting \u0026lt;- gbm(Survived ~ ., data = train_boosting, n.trees = ntree_best, interaction.depth = n_split_best, shrinkage = lambda_best) pred_boosting_comp \u0026lt;- predict(mod_boosting, newdata = test, type = \u0026quot;response\u0026quot;) pred_boosting_binary_comp \u0026lt;- ifelse(pred_boosting_comp \u0026gt; 0.5, 1, 0) submission_df \u0026lt;- data.frame(PassengerId = PassengerId_submission, Survived = pred_boosting_binary_comp) write_csv(submission_df, path = \u0026quot;submission_boosting_test.csv\u0026quot;)   Ergebnis Bei der Prognose des Testsets der Competition erzielt unser Boosting Modell mit shrinkage = 0.015, n.trees = 1000 und interaction.depth = 6 eine Accuracy von 77%.\n ","date":1598140800,"expirydate":-62135596800,"kind":"page","lang":"de","lastmod":1598204583,"objectID":"d605e9b8b60278dfa5c239bc62659e5e","permalink":"/post/hyperparametertuning-mit-cross-validation/","publishdate":"2020-08-23T00:00:00Z","relpermalink":"/post/hyperparametertuning-mit-cross-validation/","section":"post","summary":"Der Fokus dieser Analyse liegt auf dem Hyperparametertuning per Cross-Validation. Insbesondere habe ich die Cross Validation durch Schleifen selbst implementiert statt z.B. caret bzw. tidymodels dafür zu verwenden. Für die Modellierung wurde Boosting genutzt.","tags":["Boosting","for loops","Cross Validation"],"title":"Boosting: Implementierung von Hyperparameteruning per Cross Validation durch for-Schleifen","type":"post"},{"authors":["Nicolas Mollier"],"categories":null,"content":" Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   Supplementary notes can be added here, including code and math.\n","date":1554595200,"expirydate":-62135596800,"kind":"page","lang":"de","lastmod":1554595200,"objectID":"557dc08fd4b672a0c08e0a8cf0c9ff7d","permalink":"/publication/preprint/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/preprint/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example preprint / working paper","type":"publication"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Academic  Academic | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click  PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)   Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/media/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}   Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }   Questions?  Ask\n Documentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"de","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Nicolas Mollier","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   Supplementary notes can be added here, including code and math.\n","date":1441065600,"expirydate":-62135596800,"kind":"page","lang":"de","lastmod":1441065600,"objectID":"966884cc0d8ac9e31fab966c4534e973","permalink":"/publication/journal-article/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/journal-article/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example journal article","type":"publication"},{"authors":["Nicolas Mollier","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   Supplementary notes can be added here, including code and math.\n","date":1372636800,"expirydate":-62135596800,"kind":"page","lang":"de","lastmod":1372636800,"objectID":"69425fb10d4db090cfbd46854715582c","permalink":"/publication/conference-paper/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/conference-paper/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example conference paper","type":"publication"}]
[{"authors":["admin"],"categories":null,"content":"Nicolas Mollier studiert Data Science im Master an der Universität Tübingen.\n","date":1554595200,"expirydate":-62135596800,"kind":"term","lang":"de","lastmod":1554595200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/author/nicolas-mollier/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/nicolas-mollier/","section":"authors","summary":"Nicolas Mollier studiert Data Science im Master an der Universität Tübingen.","tags":null,"title":"Nicolas Mollier","type":"authors"},{"authors":["吳恩達"],"categories":null,"content":"吳恩達 is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"de","lastmod":-62135596800,"objectID":"da99cb196019cc5857b9b3e950397ca9","permalink":"/author/%E5%90%B3%E6%81%A9%E9%81%94/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E5%90%B3%E6%81%A9%E9%81%94/","section":"authors","summary":"吳恩達 is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.","tags":null,"title":"吳恩達","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Academic\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further talk details can easily be added to this page using Markdown and $\\rm \\LaTeX$ math code.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"de","lastmod":1906549200,"objectID":"96344c08df50a1b693cc40432115cbe3","permalink":"/talk/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example/","section":"talk","summary":"An example talk using Academic's Markdown slides feature.","tags":[],"title":"Example Talk","type":"talk"},{"authors":[],"categories":[],"content":" Eine Analyse für die Teilnahme an der Titanic Machine Learning Competition. In dieser Competition geht es darum, möglichst akkurat vorherzusagen, welche der Passagiere der Titanic überleben und welche nicht. Das Hauptaugenmerk dieser Analyse liegt auf dem Hyperparametertuning per Cross-Validation. Insbesondere wollte ich die Cross Validation durch Schleifen selbst inmplementieren statt z.B. caret bzw tidymodels dafür zu verwenden. Für die Modellierung wurde Boosting verwendet. Zwar wurde eine Auswahl aus den zur Verfügung stehenden Prädiktoren getroffen. Eine elaborierte analytische Auswahl der zu verwendenden Prädiktoren und deren Transformation wurden allerdings ausgeklammert. Packages library(tidyverse) library(knitr) library(kableExtra) library(mice) library(caret) library(modelr) library(plotROC) library(randomForest) library(boot) library(gbm) library(scales) library(e1071)  Load the Data Im ersten Schritt laden wir den Trainingsdatensatz und den Testdatensatz, nachdem wir beide unter https://www.kaggle.com/c/titanic/data heruntergeladen haben. Anschließend verknüpfe ich den Trainings- und Testdatensatz zu einem Datensatz, um das Pre-Processing für beide gleichzeitig durchführen zu können. Dazu ist es notwendig, die Observationen der Trainingsdaten als solche kenntlich zu machen und bei den Testdaten die Variable Survived zu ergänzen, welche in jeder der Testobservationen den Wert NA enthält.\ntrain \u0026lt;- read.csv(file = \u0026quot;train.csv\u0026quot;, header = TRUE, stringsAsFactors = FALSE) test \u0026lt;- read.csv(file = \u0026quot;test.csv\u0026quot;, header = TRUE, stringsAsFactors = FALSE) PassengerId_submission \u0026lt;- test$PassengerId train$IsTrain \u0026lt;- rep(TRUE, nrow(train)) test$IsTrain \u0026lt;- rep(FALSE, nrow(test)) test$Survived \u0026lt;- rep(NA, nrow(test)) titanic \u0026lt;- rbind(train, test)  Data Inspection Der Datensatz enthält 13 Variablen (Die Indikatorvariable IsTrain ausgenommen). Für die Prognose der Variablen Survived stehen also zunächst 11 Variablen zur Verfügung. Der Testdatensatz umfasst 891 Observationen, der Trainingsdatensatz 418.\nglimpse(titanic) head(titanic) summary(titanic)  Unter den Prädiktorvariablen enthalten Age, Fare, Cabin und Embarked fehlende Werte. Die Variable Age enthält 263 fehlende Werte. Bei der Variablen Fare fehlt lediglich bei einer Observation ein Wert. Cabin hat 1014 Missings und Embarked weist 2 Missings auf.\nBei der ersten Untersuchung ist mir eine Unstimmigkeit in den Daten aufgefallen. Zwei Namen tauchen doppelt auf: Connolly, Miss. Kate und Kelly, Mr. James. Allerdings unterscheiden sich die Ausprägungen der anderen Variablen für die jeweiligen Passagiere mit gleichem Namen. PassengerID, Age und Ticketnummer unterscheiden sich jeweils. Außerdem handelt es sich um nicht unübliche Vor- und Nachnamen, sodass davon auszugehen ist, dass es sich um unterschiedliche Personen gleichen Namens handelt.\ntitanic %\u0026gt;% count(Name) %\u0026gt;% filter(n \u0026gt; 1) titanic %\u0026gt;% filter(Name %in% duplicate_names)  Pre-Processing: Umgang mit Missings Sowohl bei Age als auch bei Fare wurden die fehlenden Werte durch den Median der jeweiligen Variablen ersetzt. Zusätzlich wurde eine neue Variable age_missing kreiert, die anzeigt, ob die entsprechende Observation einen fehlenden Wert in der Variable Age aufweist. Für die Variable Cabin wurde eine neue Faktorstufe für die 1014 fehlenden Werte geschaffen. Observationen mit Missings in Variable Embarked werden entfernt, da lediglich zwei Observationen Missings in dieser Variable aufweisen. Würde man an dieser Stelle wie bei Cabin eine neue Faktorstufe (Missing) erzeugen, würde dies später in der Modellierung zu Problemen führen, falls nicht sowohl der Datensatz an dem das Modell trainiert wird als auch der Datensatz, an dem das Modell validiert wird, eine der zwei Observationen mit Ausprägung (Missing) enthalten. Da an späterer Stelle auch Cross-Validation eingesetzt wird, wäre es sehr wahrscheinlich, dass es zu der Situation käme, in der im Testdatensatz Faktorstufen auftauchen, die im Trainingsdatensatz nicht vorkamen.\ntitanic %\u0026gt;% mutate(age_missing = is.na(Age)) %\u0026gt;% group_by(age_missing) %\u0026gt;% summarize(surival_rate = mean(Survived, na.rm = T)) titanic \u0026lt;- titanic %\u0026gt;% mutate(age_missing = is.na(Age)) titanic$Age[is.na(titanic$Age)] \u0026lt;- median(titanic$Age, na.rm = TRUE) titanic$Fare[is.na(titanic$Fare)] \u0026lt;- median(titanic$Fare, na.rm = TRUE) titanic$Cabin[titanic$Cabin == \u0026#39;\u0026#39;] \u0026lt;- NA titanic \u0026lt;- titanic %\u0026gt;% filter(!(Embarked == \u0026#39;\u0026#39;)) titanic \u0026lt;- titanic %\u0026gt;% mutate(cabin_missing = is.na(Cabin))  Die kategorialen Variablen wurden zu Faktorvariablen umgewandelt.\ntitanic$PassengerId \u0026lt;- factor(titanic$PassengerId) titanic$Survived \u0026lt;- factor(titanic$Survived) titanic$Pclass \u0026lt;- factor(titanic$Pclass) titanic$Sex \u0026lt;- factor(titanic$Sex) titanic$Embarked \u0026lt;- factor(titanic$Embarked) titanic$age_missing \u0026lt;- factor(titanic$age_missing) titanic$cabin_missing \u0026lt;- factor(titanic$cabin_missing) #titanic$Cabin \u0026lt;- fct_explicit_na(titanic$Cabin)  Modellierung Zur Prognose der Variablen Survived wurde Boosting verwendet. Zuvor wurde der Gesamtdatensatz nach erfolgter Behandlung der Missings wieder in den Trainingsdatensatz und den Testdatensatz aufgeteilt. Außerdem wurden Variablen, die Passagiere eindeutig oder zumindest sehr genau individuell identifizieren können, nicht als Prädiktoren für die Prognose verwendet, um ein Overfitting der Modelle zu vermeiden. Deshalb wurden die Variablen PassengerId, Name, Ticket und Cabin entfernt.\nunique(titanic$PassengerId) %\u0026gt;% length() unique(titanic$Name) %\u0026gt;% length() unique(titanic$Ticket) %\u0026gt;% length() table(titanic$Cabin) train \u0026lt;- titanic %\u0026gt;% filter(IsTrain) %\u0026gt;% dplyr::select(-PassengerId, -IsTrain, -Name, -Ticket, -Cabin) test \u0026lt;- titanic %\u0026gt;% filter(!IsTrain) %\u0026gt;% dplyr::select(-PassengerId, -IsTrain, -Name, -Ticket, -Cabin, -Survived) Wir spalten die Trainingsdaten train in titanic_train und titanic_test auf. titanic_train wird für das Parametertuning per Cross Validation verwendet. Mit titanic_test bewerten wir das anhand von titanic_train mit den besten Parameterwerten trainierte Modell. Die Accuracy, die wir beim Test an titanic_test erhalten, dient als Schätzung für die Accuracy, die bei Submission auf Kaggle zu erwarten ist.\nset.seed(1234) train_split \u0026lt;- caret::createDataPartition(train$Survived, p = 0.75, list = FALSE) titanic_train \u0026lt;- train[train_split,] titanic_test \u0026lt;- train[-train_split,] Boosting Beim Boosting wird jeder Decision Tree auf einer modifizierten Version der Trainingsdaten trainiert. Bei jedem der trainierten Decision Trees werden die Informationen der vorherigen Trees genutzt, indem die Residuals des vorherigen Trees als abhängige Variable genutzt werden. Somit legt jeder folgende Baum besonderes Gewicht auf die Observationen, die von dem vorherigen Baum schlecht vorhergesagt wurden. Wie schnell dieser Lernvorgang geschieht, wird durch den Hyperparameter shrinkage bestimmt. Weitere zu bestimmende Hyperparameter sind die Anzahl der Bäume B und die Anzahl der Splits pro Baum d. Die Hyperparameter werden durch Cross Validation an titanic_train bestimmt. Zunächst wird für jeden Hyperparameter eine Sequenz möglicher Werte gebildet und ein Grid names boosting_parameters erstellt, das alle möglichen Kombinationen der Werte der verschiedenen Hyperparameter enthält. Anschließend bilde ich den Vektor folds der die Indizes enthält, die genutzt werden, um eine Observation innerhalb der Cross Validation entweder dem Training des jeweiligen Modells oder dem Assessment zuzordnen. Für die Implementierung der Cross Validation verwende ich zwei ineinander verschachtelte for-Schleifen. Die erste SChleife iteriert über alle Kombinationen der Hyperparameter, die zweite Schleife iteriert über alle k Stufen der Cross Validation. Jede der k Folds wird in einer der k Stufen einmal dem Assessment des Modells dienen und in den anderen k-1 Stufen zum Trainieren des Modells verwendet.\nntrees \u0026lt;- seq(50, 200, 25) lambda \u0026lt;- c(0.001, 0.005, 0.01, 0.015, 0.02) n_splits \u0026lt;- seq(1, 4, 1) boosting_parameters \u0026lt;- expand_grid(ntrees, lambda, n_splits) boosting_parameters \u0026lt;- boosting_parameters %\u0026gt;% mutate(id = 1:nrow(boosting_parameters)) set.seed(1234) k \u0026lt;- 5 folds \u0026lt;- sample(1:k, size = nrow(titanic_train), replace = TRUE) boosting_accuracy \u0026lt;- matrix(NA, nrow = k, ncol = nrow(boosting_parameters), dimnames = list(NULL, boosting_parameters$id)) titanic_train_boosting \u0026lt;- titanic_train titanic_train_boosting$Survived \u0026lt;- as.character(titanic_train_boosting$Survived) for(i in 1:nrow(boosting_parameters)){ n.trees \u0026lt;- boosting_parameters$ntrees[i] shrinkage \u0026lt;- boosting_parameters$lambda[i] interaction.depth \u0026lt;- boosting_parameters$n_splits[i] for(j in 1:k){ df_train \u0026lt;- titanic_train_boosting[j != folds,] df_test \u0026lt;- titanic_train_boosting[j == folds,] fit \u0026lt;- gbm(Survived ~ ., data = df_train, n.trees = n.trees, interaction.depth = interaction.depth, shrinkage = shrinkage) pred \u0026lt;- predict(fit, newdata = df_test, type = \u0026quot;response\u0026quot;) pred_binary \u0026lt;- ifelse(pred \u0026gt; 0.5, 1, 0) %\u0026gt;% factor(levels = c(0, 1)) conf_matrix \u0026lt;- caret::confusionMatrix(data = pred_binary, reference = factor(df_test$Survived, levels = c(0,1)), positive = \u0026quot;1\u0026quot;) boosting_accuracy[j, i] \u0026lt;- conf_matrix$overall[\u0026quot;Accuracy\u0026quot;] } } accuracy_mean \u0026lt;- colMeans(boosting_accuracy) cv_accuracy \u0026lt;- accuracy_mean[which.max(accuracy_mean)] best_comb_boosting \u0026lt;- boosting_parameters[which.max(accuracy_mean),] Nachdem beide Schleifen durchlaufen sind, erhalten wir eine Matrix, die für jede Kombination der Hyperparameter in jeder Stufe der Cross Validation die Accuracy des Modells enthält.\ncustom_kable \u0026lt;- function(data, fontsize = 12, fullwidth = FALSE){ knitr::kable(data) %\u0026gt;% kable_styling(font_size = fontsize, full_width = fullwidth) } boosting_accuracy %\u0026gt;% custom_kable() Die höchste Accuracy wird mit einem Modell erzielt, dass 200 Bäume mit je 4 Splits und einer Lernrate (shrinkage) von 0.02 verwendet. Alle Observationen, die eine prognostizierte Wahrscheinlichkeit von über 0.5 aufweisen, werden als Überlebend klassifiziert. Das Modell mit den gemäß Cross Validation besten Parameterwerten für B, d und shrinkage erzielt eine Cross Validation Accuracy von 84.37%.\nZur abschließenden Bewertung des Modells bewerten wir die Prognosen des Modells mit den soeben gefundenen Hyperparametern an dem Datensatz titanic_test, der nicht an der Auswahl der Hyperparameter beteiligt war.\nntree_best \u0026lt;- best_comb_boosting[[\u0026quot;ntrees\u0026quot;]] n_split_best \u0026lt;- best_comb_boosting[[\u0026quot;n_splits\u0026quot;]] lambda_best \u0026lt;- best_comb_boosting[[\u0026quot;lambda\u0026quot;]] boosting_fit \u0026lt;- gbm(Survived ~ ., data = titanic_train_boosting, n.trees = ntree_best, interaction.depth = n_split_best, shrinkage = lambda_best) pred_boosting_titanic_test \u0026lt;- predict(boosting_fit, newdata = titanic_test, type = \u0026quot;response\u0026quot;) pred_boosting_binary_titanic_test \u0026lt;- ifelse(pred_boosting_titanic_test \u0026gt; 0.5, 1, 0) %\u0026gt;% factor(levels = c(0, 1)) conf_matrix \u0026lt;- caret::confusionMatrix(data = pred_boosting_binary_titanic_test, reference = factor(titanic_test$Survived, levels = c(0,1)), positive = \u0026quot;1\u0026quot;) accuracy \u0026lt;- list() accuracy$boosting \u0026lt;- conf_matrix$overall[\u0026quot;Accuracy\u0026quot;] Die Schätzung der Accuracy beträgt 79.28%. Zum Schluss bestimmen wir mit dem Boosting Modell die Prognosen für den Testdatensatz, speichern sie als csv file ab und reichen sie anschließend auf Kaggle als Submission ein.\ntrain_boosting \u0026lt;- train train_boosting$Survived \u0026lt;- as.character(train_boosting$Survived) mod_boosting \u0026lt;- gbm(Survived ~ ., data = train_boosting, n.trees = ntree_best, interaction.depth = n_split_best, shrinkage = lambda_best) pred_boosting_comp \u0026lt;- predict(mod_boosting, newdata = test, type = \u0026quot;response\u0026quot;) pred_boosting_binary_comp \u0026lt;- ifelse(pred_boosting_comp \u0026gt; 0.5, 1, 0) submission_df \u0026lt;- data.frame(PassengerId = PassengerId_submission, Survived = pred_boosting_binary_comp) write_csv(submission_df, path = \u0026quot;submission.csv\u0026quot;)   Ergebnis Bei der Prognose des Testsets der Competition erzielt unser Boosting Modell mit shrinkage = 0.02, n.trees = 200 und interaction.depth = 4 eine Accuracy von 77%.\n ","date":1598140800,"expirydate":-62135596800,"kind":"page","lang":"de","lastmod":1598204583,"objectID":"d605e9b8b60278dfa5c239bc62659e5e","permalink":"/post/hyperparametertuning-mit-cross-validation/","publishdate":"2020-08-23T00:00:00Z","relpermalink":"/post/hyperparametertuning-mit-cross-validation/","section":"post","summary":"Eine Analyse für die Teilnahme an der Titanic Machine Learning Competition. In dieser Competition geht es darum, möglichst akkurat vorherzusagen, welche der Passagiere der Titanic überleben und welche nicht. Das Hauptaugenmerk dieser Analyse liegt auf dem Hyperparametertuning per Cross-Validation.","tags":[],"title":"Kaggle: Titanic Machine Learning Competition","type":"post"},{"authors":["Nicolas Mollier"],"categories":null,"content":" Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   Supplementary notes can be added here, including code and math.\n","date":1554595200,"expirydate":-62135596800,"kind":"page","lang":"de","lastmod":1554595200,"objectID":"557dc08fd4b672a0c08e0a8cf0c9ff7d","permalink":"/publication/preprint/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/preprint/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example preprint / working paper","type":"publication"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Academic  Academic | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click  PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)   Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/media/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}   Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }   Questions?  Ask\n Documentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"de","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Nicolas Mollier","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   Supplementary notes can be added here, including code and math.\n","date":1441065600,"expirydate":-62135596800,"kind":"page","lang":"de","lastmod":1441065600,"objectID":"966884cc0d8ac9e31fab966c4534e973","permalink":"/publication/journal-article/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/journal-article/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example journal article","type":"publication"},{"authors":["Nicolas Mollier","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   Supplementary notes can be added here, including code and math.\n","date":1372636800,"expirydate":-62135596800,"kind":"page","lang":"de","lastmod":1372636800,"objectID":"69425fb10d4db090cfbd46854715582c","permalink":"/publication/conference-paper/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/conference-paper/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example conference paper","type":"publication"}]